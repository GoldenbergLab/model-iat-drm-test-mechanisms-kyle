{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kjl113\\AppData\\Local\\Temp\\ipykernel_21276\\3266697596.py:2: DtypeWarning: Columns (36,44,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  controlfile = pd.read_csv('ideology_exploratory.csv', delimiter=',', index_col=False)\n",
      "C:\\Users\\kjl113\\AppData\\Local\\Temp\\ipykernel_21276\\3266697596.py:3: DtypeWarning: Columns (36,44,46,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  maskcontrolfile = pd.read_csv('ideology_confirmatory_masked.csv', delimiter=',', index_col=False)\n"
     ]
    }
   ],
   "source": [
    "# read trial-level IAT data (basefile) and subject-level experiment data (controlfile)\n",
    "basefile = pd.read_csv('iat_exp_raw.csv', delimiter=',', index_col=False)\n",
    "controlfile = pd.read_csv('ideology_exploratory.csv', delimiter=',', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "\n",
    "# make a dictionary of trial-level IAT data with separate keys for each IAT\n",
    "# first add the good/bad standard IATs (note that not all are included in the loop because not all task names map onto desired key names, e.g. typo in riskycautious in raw data)\n",
    "for x in ['possiblecertain', 'labormanagement', 'statechurch', 'socialismcapitalism', 'complexsimple', 'protestaccept',\n",
    "          'fairbiased', 'democracyfascism', 'motherfather', 'hopeduty', 'selfother', 'regulationmarkets',\n",
    "          'progressrestore', 'newold', 'non-profitscorporations', '20501950', 'ambiguousclear',\n",
    "          'defendattack', 'changepreserve', 'collectiveindividual', 'communityindividual', 'individualgroup',\n",
    "          'forwardbackward', 'equalunequal', 'anarchyhierarchy', 'justiceinjustice',\n",
    "          'novelfamiliar', 'foreignlocal', 'nurturingstrict', 'presentpast', ]:\n",
    "    df_dict[x] = basefile[basefile['task_name'].isin(['i%s_gba' % x, 'i%s_gbb' % x])]\n",
    "\n",
    "# next add all the true/false standard IATs\n",
    "for x in ['dangersafety_tf', 'sciencereligion_tf', 'conspiracyaccident_tf',\n",
    "          'evolutioncreationism_tf']:\n",
    "    df_dict[x] = basefile[basefile['task_name'].isin(['i%sa' % x, 'i%sb' % x])]\n",
    "\n",
    "# add any remaining IATs (those with long names, typos, the only danger/safe IAT, and the four single-target IATs)\n",
    "df_dict['blackwhite'] = basefile[basefile['task_name'].isin(['iblackpeoplewhitepeople_gba', 'iwhitepeopleblackpeople_gbb'])]\n",
    "df_dict['gaystraight'] = basefile[basefile['task_name'].isin(['istraightpeoplegaypeople_gba', 'istraightpeoplegaypeople_gbb'])]\n",
    "df_dict['riskycautious'] = basefile[basefile['task_name'].isin(['irickycautious_gba', 'irickycautious_gbb'])]\n",
    "df_dict['futurepresent'] = basefile[basefile['task_name'].isin(['ifurturepresent_gba', 'ifurturepresent_gbb'])]\n",
    "df_dict['20501950_ds'] = basefile[basefile['task_name'].isin(['i20501950_dsa', 'i20501950_dsb'])]\n",
    "df_dict['self_ar'] = basefile[basefile['task_name'].isin(['iself_ara', 'iself_arb'])]\n",
    "df_dict['self_dr'] = basefile[basefile['task_name'].isin(['iself_dra', 'iself_drb'])]\n",
    "df_dict['self_lc'] = basefile[basefile['task_name'].isin(['iself_lca', 'iself_lcb'])]\n",
    "df_dict['self_sa'] = basefile[basefile['task_name'].isin(['iself_saa', 'iself_sab'])]\n",
    "\n",
    "# make a list of IATs that we want to invert their explicit preference scores, so they're in line with testing what is defined as compatible according to Ideology codebook \n",
    "invertlist = ['20501950', 'changepreserve', 'collectiveindividual', 'communityindividual',\n",
    "              'defendattack', 'democracyfascism', 'equalunequal', 'evolutioncreationism_tf',\n",
    "              'fairbiased', 'forwardbackward', 'hopeduty', 'individualgroup', 'justiceinjustice',\n",
    "              'motherfather', 'newold', 'non-profitscorporations', 'nurturingstrict',\n",
    "              'presentpast', 'progressrestore', 'sciencereligion_tf', 'selfother', 'self_dr',\n",
    "              'self_ar', 'self_lc', 'self_sa']\n",
    "\n",
    "# make a dictionary with keys for each IAT, and all RDM thresholds for \"Action B\". Four different thresholds for four different blocks.\n",
    "accumulator_b_dict = {'20501950_ds': ['2050', 'Safety', '2050/Safety', '1950/Safety'],\n",
    "                   '20501950': ['1950', 'Bad', '1950/Bad', '2050/Bad'],\n",
    "                   'ambiguousclear': ['Ambiguous', 'Bad', 'Ambiguous/Bad', 'Clear/Bad'],\n",
    "                   'anarchyhierarchy': ['Anarchy', 'Bad', 'Anarchy/Bad', 'Hierarchy/Bad'],\n",
    "                   'changepreserve': ['Preserve', 'Bad', 'Preserve/Bad', 'Change/Bad'],\n",
    "                   'communityindividual': ['Individual', 'Bad', 'Individual/Bad', 'Community/Bad'],\n",
    "                  'collectiveindividual': ['Individual', 'Bad', 'Individual/Bad', 'Collective/Bad'],\n",
    "                  'conspiracyaccident_tf': ['Conspiracy', 'False', 'Conspiracy/False', 'Accident/False'],\n",
    "                  'defendattack': ['Attack', 'Bad', 'Attack/Bad', 'Defend/Bad'],\n",
    "                  'equalunequal': ['Unequal', 'Bad', 'Unequal/Bad', 'Equal/Bad'],\n",
    "                  'evolutioncreationism_tf': ['Creationism', 'False', 'Creationism/False', 'Evolution/False'],\n",
    "                  'foreignlocal': ['Foreign', 'Bad', 'Foreign/Bad', 'Local/Bad'],\n",
    "                  'forwardbackward': ['Backward', 'Bad', 'Backward/Bad', 'Forward/Bad'],\n",
    "                  'futurepresent': ['Future', 'Bad', 'Future/Bad', 'Present/Bad'],\n",
    "                  'hopeduty': ['Duty', 'Bad', 'Duty/Bad', 'Hope/Bad'],\n",
    "                  'individualgroup': ['Group', 'Bad', 'Group/Bad', 'Individual/Bad'],\n",
    "                  'justiceinjustice': ['Injustice', 'Bad', 'Injustice/Bad', 'Justice/Bad'],\n",
    "                  'motherfather': ['Father', 'Bad', 'Father/Bad', 'Mother/Bad'],\n",
    "                  'newold': ['Old', 'Bad', 'Old/Bad', 'New/Bad'],\n",
    "                  'non-profitscorporations': ['Corporations', 'Bad', 'Corporations/Bad', 'Non-Profits/Bad'],\n",
    "                  'novelfamiliar': ['Novel', 'Bad', 'Novel/Bad', 'Familiar/Bad'],\n",
    "                  'nurturingstrict': ['Strict', 'Bad', 'Strict/Bad', 'Nurturing/Bad'],\n",
    "                  'presentpast': ['Past', 'Bad', 'Past/Bad', 'Present/Bad'],\n",
    "                  'progressrestore': ['Restore', 'Bad', 'Restore/Bad', 'Progress/Bad'],\n",
    "                  'regulationmarkets': ['Regulation', 'Bad', 'Regulation/Bad', 'Markets/Bad'],\n",
    "                  'sciencereligion_tf': ['Religion', 'False', 'Religion/False', 'Science/False'],\n",
    "                  'blackwhite': ['Black People', 'Bad', 'Black People/Bad', 'White People/Bad'],\n",
    "                  'gaystraight': ['Gay People', 'Bad', 'Gay People/Bad', 'Straight People/Bad'],\n",
    "                  'riskycautious': ['Risky', 'Bad', 'Risky/Bad', 'Cautious/Bad'],\n",
    "                  'possiblecertain': ['Possible', 'Bad', 'Possible/Bad', 'Certain/Bad'],\n",
    "                  'labormanagement': ['Labor', 'Bad', 'Labor/Bad', 'Management/Bad'],\n",
    "                  'statechurch': ['State', 'Bad', 'State/Bad', 'Church/Bad'],\n",
    "                  'socialismcapitalism': ['Socialism', 'Bad', 'Socialism/Bad', 'Capitalism/Bad'],\n",
    "                  'complexsimple': ['Complex', 'Bad', 'Complex/Bad', 'Simple/Bad'],\n",
    "                  'protestaccept': ['Protest', 'Bad', 'Protest/Bad', 'Accept/Bad'],\n",
    "                  'fairbiased': ['Biased', 'Bad', 'Biased/Bad', 'Fair/Bad'],\n",
    "                  'democracyfascism': ['Fascism', 'Bad', 'Fascism/Bad', 'Democracy/Bad'],\n",
    "                  'dangersafety_tf': ['Danger', 'False', 'Danger/False', 'Safety/False'],\n",
    "                  'selfother': ['Other', 'Bad', 'Other/Bad', 'Self/Bad'],\n",
    "                  'self_ar': ['Atheist', 'Atheist/Self'],\n",
    "                  'self_dr': ['Republican', 'Republican/Self'],\n",
    "                  'self_lc': ['Conservative', 'Conservative/Self'],\n",
    "                  'self_sa': ['Anger', 'Anger/Self']}\n",
    "\n",
    "# make a dictionary of blocks with keys for each IAT. Blocks are recorded as integers for Stan to use as indices. \n",
    "# concept-only block = 1, attribute-only block = 2, compatible block = 3, incompatible block = 4\n",
    "# for single-target IATs, concept-only block = 2, compatible block = 3, incompatible block = 4\n",
    "block_dict = {}\n",
    "for y in list(df_dict.keys()):\n",
    "      tempdict = {}\n",
    "      if len(accumulator_b_dict[y]) == 4 and y!='clintonbush_ch':\n",
    "            x = accumulator_b_dict[y]\n",
    "            tempdict['%s,%s' % (x[0],x[3].split('/')[0])] = 1\n",
    "            tempdict['%s,%s' % (x[3].split('/')[0],x[0])] = 1\n",
    "            if x[1] == 'Bad':\n",
    "                  tempdict['Good,Bad'] = 2\n",
    "                  tempdict['%s/Good,%s' % (x[3].split('/')[0], x[2])] = 3\n",
    "                  tempdict['%s/Good,%s' % (x[0], x[3])] = 4\n",
    "            elif x[1] == 'False':\n",
    "                  tempdict['True,False'] = 2\n",
    "                  tempdict['%s/True,%s' % (x[3].split('/')[0], x[2])] = 3\n",
    "                  tempdict['%s/True,%s' % (x[0], x[3])] = 4\n",
    "            elif x[1] == 'Safety':\n",
    "                  tempdict['Danger,Safety'] = 2\n",
    "                  tempdict['%s/Danger,%s' % (x[3].split('/')[0], x[2])] = 3\n",
    "                  tempdict['%s/Danger,%s' % (x[0], x[3])] = 4\n",
    "            block_dict[y] = tempdict\n",
    "      elif len(accumulator_b_dict[y]) == 2:\n",
    "            if y == 'self_ar':\n",
    "                  tempdict['Atheist,Religious'] = 2\n",
    "                  tempdict['Atheist,Religious/Self'] = 3\n",
    "                  tempdict['Atheist/Self,Religious'] = 4\n",
    "            if y == 'self_dr':\n",
    "                  tempdict['Democrat,Republican'] = 2\n",
    "                  tempdict['Democrat/Self,Republican'] = 3\n",
    "                  tempdict['Democrat,Republican/Self'] = 4\n",
    "            if y == 'self_lc':\n",
    "                  tempdict['Liberal,Conservative'] = 2\n",
    "                  tempdict['Liberal/Self,Conservative'] = 3\n",
    "                  tempdict['Liberal,Conservative/Self'] = 4\n",
    "            if y == 'self_sa':\n",
    "                  tempdict['Sadness,Anger'] = 2\n",
    "                  tempdict['Sadness/Self,Anger'] = 3\n",
    "                  tempdict['Sadness,Anger/Self'] = 4\n",
    "            block_dict[y] = tempdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(iat='blackwhite', save=False):\n",
    "\n",
    "    df = df_dict[iat].copy() # get trial-level data for selected IAT\n",
    "    accumulator_b = accumulator_b_dict[iat] # get list of labels for \"Action B\", the second accumulator in each of the four blocks\n",
    "\n",
    "    df = df[df['trial_error'] == 0] # limit the data to only correct responses (error trials have confounded RTs, and we're instead interested in evidence accumulation toward either action when correct)\n",
    "    df = df[['session_id', 'trial_response', 'trial_latency', 'block_pairing_definition']] # limit data to what we need for Stan (ID, action, RT, and block)\n",
    "    df = df.dropna(axis=0).reset_index(drop=True) # of these limited data, drop any trials that are missing the information needed for Stan\n",
    "\n",
    "    # convert the nominal variables into integers for Stan\n",
    "    df['trial_response'] = [1 if x in accumulator_b else 2 for x in df['trial_response']]\n",
    "    df['block_pairing_definition'] = [block_dict[iat][x] for x in df['block_pairing_definition']]\n",
    "\n",
    "    print('Number of original subjects: %s' % len(df['session_id'].unique()))\n",
    "\n",
    "    # remove any subjects that lack minimal variability in their actions within blocks; this is mostly due to incomplete sessions / missing blocks\n",
    "    dellist = []\n",
    "    for x in df['session_id'].unique():\n",
    "        for y in df['block_pairing_definition'].unique():\n",
    "            temp = df[df['session_id']==x]\n",
    "            if list(temp[temp['block_pairing_definition']==y]['trial_response']).count(1) < 2:\n",
    "                dellist.append(x)\n",
    "            elif list(temp[temp['block_pairing_definition']==y]['trial_response']).count(2) < 2:\n",
    "                dellist.append(x)\n",
    "    print('Number of subjects thrown out due to no variation OR missing entire blocks: %s' % len(np.unique(dellist)))\n",
    "    df = df[~df['session_id'].isin(dellist)]\n",
    "\n",
    "    # remove any observations where rt <= 100ms - these are likely false starts\n",
    "    df = df[df['trial_latency'] > 100]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # remove any observations where rt > 5s - these are likely distractions\n",
    "    df = df[df['trial_latency'] < 5000]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # remove any subjects with too few trials (at least 10 trials per block)\n",
    "    dellist = []\n",
    "    for x in df['session_id'].unique():\n",
    "        for y in df['block_pairing_definition'].unique():\n",
    "            temp = df[df['session_id']==x]\n",
    "            if len(temp[temp['block_pairing_definition']==y]) < 10:\n",
    "                dellist.append(x)\n",
    "    print('Number of subjects thrown out due to too few trials for each block (<10): %s' % len(np.unique(dellist)))\n",
    "    df = df[~df['session_id'].isin(dellist)]     \n",
    "\n",
    "    print('Number of subjects remaining: %s' % len(df['session_id'].unique()))\n",
    "    subs = np.unique(df['session_id']) # get a list of unique subjects\n",
    "\n",
    "    # make lists for experiment data\n",
    "    dlist = [] # d-scores will go here\n",
    "    session_id_list = [] # list of subjects who will get subject-level estimates in Stan\n",
    "    session_id_list_ind = [] # index for each subject who will get subject-level estimates in Stan\n",
    "    session_id_list_counter = 1 \n",
    "    explist = [] # positive values are in favor of x\n",
    "    sssubtract_list = []\n",
    "\n",
    "    # populate the above lists by looping through each subject\n",
    "    for x in subs:\n",
    "        temp = controlfile[controlfile['session_id']==x].reset_index() # get experimental data for the subject\n",
    "        if any(iat in task for task in [str(temp['task_%s' % t][0]) for t in [1, 2, 3, 4, 5, 6, 7, 8]]): # if the IAT was performed by the participant, and this is reflected in the experiment-level data\n",
    "            incompatible = list(df[df['session_id']==x].loc[df['block_pairing_definition']==4]['trial_latency']) # get RTs for the subjects incompatible block\n",
    "            compatible = list(df[df['session_id']==x].loc[df['block_pairing_definition']==3]['trial_latency']) # get RTs for the subjects compatible block\n",
    "            dlist.append((np.mean(incompatible) - np.mean(compatible)) / np.std(incompatible + compatible)) # calculate D-score and append to list\n",
    "        else:\n",
    "            dlist.append(np.nan) # if no IAT listed in experimental data, append nan for this participant (they'll be excluded from Stan)\n",
    "        if type(temp['explicit_task_full'][0]) == str: # if their experimental data reflects that an explicit preference thermometer was performed\n",
    "            if all(x in temp['explicit_task_full'][0] for x in iat.split('_')): # and the IAT topic in question is what was evaluated\n",
    "                if iat in invertlist: # get explicit preference score and append to list. Invert the score if in the invertlist so they're in line with testing what is defined as compatible according to Ideology codebook\n",
    "                    explist.append(temp['exp_att'][0])\n",
    "                else:\n",
    "                    explist.append(temp['exp_att'][0]*(-1))\n",
    "            else:\n",
    "                explist.append(np.nan)\n",
    "        else:\n",
    "            explist.append(np.nan) \n",
    "        if np.isnan(temp['culp_x'][0]) == False and np.isnan(temp['culp_y'][0]) == False and type(temp['explicit_task_full'][0]) == str and all(x in temp['explicit_task_full'][0] for x in iat.split('_')):\n",
    "            sssubtract_list.append(True) # For exploratory analysis only, to save compute time, limit the pool of subjects who will recieve subject-specific estimates to those that also had culp_x and culp_y records. We'll remove this for confirmatory\n",
    "        else:\n",
    "            sssubtract_list.append(np.nan)\n",
    "        if not np.isnan(dlist[-1]) and not np.isnan(explist[-1]) and not np.isnan(sssubtract_list[-1]): # if the subject has a d-score, explicit preference score, and is to be included in the exloratory analysis\n",
    "            session_id_list_ind.append(session_id_list_counter) # append an index for the participant\n",
    "            session_id_list.append(1) # append 1 to the id list so we can identify that this subject out of the entire pool will recieve subject-specific estimates\n",
    "            session_id_list_counter += 1\n",
    "        else:\n",
    "            session_id_list.append(0)\n",
    "            session_id_list_ind.append(0)\n",
    "\n",
    "    standf = pd.DataFrame({'d': dlist, 'exp': explist, 'sstot': sssubtract_list}).dropna()\n",
    "    print('Number of subjects with d-score AND explicit preference AND selected for subject-specific estimates: %s' % len(standf))\n",
    "\n",
    "    # loop through every trial in the trial-level df, and assign an index to each unique subject. These indices will be used by Stan\n",
    "    sub_ids = list(df['session_id'])\n",
    "    new_inds = []\n",
    "    counter = 1\n",
    "    for i, x in enumerate(sub_ids):\n",
    "        if i != 0:\n",
    "            if x != sub_ids[i-1]:\n",
    "                counter += 1\n",
    "        new_inds.append(counter)\n",
    "\n",
    "    # final dictionary for Stan data block\n",
    "    data = {\n",
    "        'N': len(df['session_id'].unique()), # number of unique subjects (everyone who completed the IAT)\n",
    "        'T': len(df), # total number of observations\n",
    "        'N_sub': np.sum(session_id_list), # total number of subjects who will get subject-level estimates (~10% for exploratory, ~50% for confirmatory)\n",
    "        'N_ind': new_inds, # indices for each unique subject\n",
    "        'N_sub_ind': session_id_list_ind, # indices for each subject who will get subject-level estimates\n",
    "        'N_cond': 4, # total number of conditions / blocks\n",
    "        'grainsize': int(round(len(df)) / 4), # grainsize for Stan to parallelize log-likelihood calculations. Not necessary.\n",
    "        'condition': list(df['block_pairing_definition']), # conditions for each observation\n",
    "        'RT': list(df['trial_latency']), # rts for each observation\n",
    "        'choice': list(df['trial_response']), # choice for each observation\n",
    "        'sub_id': sub_ids # participant ID\n",
    "    }\n",
    "\n",
    "    if save == True:\n",
    "        standf.to_csv('%s.csv' % iat, index=False) # save a csv with all the d-scores and explicit preferences\n",
    "        with open(\"%s.pkl\" % iat, \"wb\") as f:\n",
    "            pickle.dump(data, f, protocol=-1) # save a pickle with the trial-level data for Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original subjects: 1076\n",
      "Number of subjects thrown out due to no variation OR missing entire blocks: 176\n",
      "Number of subjects thrown out due to too few trials for each block (<10): 13\n",
      "Number of subjects remaining: 887\n",
      "Number of subjects with d-score AND explicit preference AND selected for subject-specific estimates: 91\n"
     ]
    }
   ],
   "source": [
    "# run this for each IAT\n",
    "analyze('blackwhite', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
